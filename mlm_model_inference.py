from transformers import pipeline

MODEL_PATH = "./old_rus_bert_best/checkpoint-3600"


fill_mask = pipeline(
    "fill-mask",
    model=MODEL_PATH,
    tokenizer=MODEL_PATH
)

def test_model(text):
    print(f"\nüìñ Text: {text}")
    results = fill_mask(text)
    for res in results[:3]:
        print(f"   {res['score']:.1%} -> {res['token_str']}")


texts = [
"–ø–æ–∫–ª–æ–Ω–æ —ø –æ–Ω—≥–∏–º–∞ –∫–æ [MASK]",
"–∞ –ø–æ—Å—É–ª–æ–≤ –±–æ—è—Ä–æ–º –∏ –æ–∫–æ–ª–Ω–∏—á–∏–º –Ω–µ [MASK]",
"–∑–∞ –º–ª—Ç–≤—π —Å—Ç—Ö—ä —°—Ü—å –Ω–∞—à–∏—Ö –≥–∏ —ó—Å–µ —Ö–µ —Å–Ω–µ –±–∂—ó–∏ [MASK] –º—ß",
"–≤–æ –∏–º—ß —ø—Ü“É–∞ –∏ [MASK] –∏ —Å—Ç“É–≥–æ –¥—Ö“É–∞",
"–≥–æ—Å–ø–æ–¥–∏ [MASK] –º—ß –≥—Ä—£—à–Ω–∏–∫–∞"
]
for text in texts:
    test_model(text)